{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd75073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "     ---------------------------------------- 12.1/12.1 MB 6.5 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "     -------------------------------------- 122.3/122.3 kB 7.0 MB/s eta 0:00:00\n",
      "Collecting thinc<8.3.0,>=8.1.8\n",
      "  Downloading thinc-8.2.2-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 10.5 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "     ------------------------------------- 479.7/479.7 kB 10.0 MB/s eta 0:00:00\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "     ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.9/45.9 kB ? eta 0:00:00\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "     ------------------------------------- 381.9/381.9 kB 12.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (23.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.6/181.6 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.24.2)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting pydantic-core==2.14.5\n",
      "  Downloading pydantic_core-2.14.5-cp311-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 12.0 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "     ---------------------------------------- 6.6/6.6 MB 11.4 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 kB ? eta 0:00:00\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: cymem, wasabi, typing-extensions, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, cloudpathlib, click, catalogue, blis, annotated-types, typer, srsly, pydantic-core, preshed, pydantic, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.5.2 pydantic-core-2.14.5 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.2 typer-0.9.0 typing-extensions-4.9.0 wasabi-1.1.2 weasel-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "     --------------------------------------- 24.0/24.0 MB 11.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\jade rosales\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n",
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b481af9-3e7a-4407-8bde-8d01b5d3b738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# Download spaCy's English NLP model\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load spaCy's English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56591d37-365b-4b44-b0a2-f00900104823",
   "metadata": {},
   "source": [
    "# Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f72f3c3a-5ca9-4272-8d27-c5af9b0754c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "documents = [\n",
    "    \"Machine learning involves algorithms that improve automatically through experience.\",\n",
    "    \"Deep learning is a subset of machine learning based on artificial neural networks.\",\n",
    "    \"Reinforcement learning is a type of machine learning technique.\",\n",
    "    \"Supervised and unsupervised learning are two main types of machine learning.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04ad12-95ea-4a0a-ac49-f4ee9fbaeee2",
   "metadata": {},
   "source": [
    "# Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97f87a2-a9f4-4557-aef6-c921bda4e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize and lemmatize using spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all documents\n",
    "processed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05542fa2-2765-4327-bb81-27e6b2d629ef",
   "metadata": {},
   "source": [
    "# Print topics and their keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f567bec-dfdf-4dd8-80b3-169eb11aa978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.234*\"learning\" + 0.121*\"machine\" + 0.084*\"type\" + 0.047*\"network\" + '\n",
      "  '0.047*\"artificial\" + 0.047*\"base\" + 0.047*\"subset\" + 0.047*\"deep\" + '\n",
      "  '0.047*\"neural\" + 0.047*\"supervise\"'),\n",
      " (1,\n",
      "  '0.053*\"machine\" + 0.053*\"learning\" + 0.053*\"reinforcement\" + '\n",
      "  '0.053*\"technique\" + 0.053*\"main\" + 0.053*\"unsupervised\" + 0.053*\"supervise\" '\n",
      "  '+ 0.053*\"type\" + 0.053*\"neural\" + 0.053*\"subset\"'),\n",
      " (2,\n",
      "  '0.053*\"machine\" + 0.053*\"learning\" + 0.053*\"reinforcement\" + '\n",
      "  '0.053*\"technique\" + 0.053*\"supervise\" + 0.053*\"main\" + 0.053*\"unsupervised\" '\n",
      "  '+ 0.053*\"type\" + 0.053*\"neural\" + 0.053*\"deep\"'),\n",
      " (3,\n",
      "  '0.106*\"machine\" + 0.106*\"experience\" + 0.106*\"automatically\" + '\n",
      "  '0.106*\"improve\" + 0.106*\"involve\" + 0.106*\"algorithm\" + 0.106*\"learning\" + '\n",
      "  '0.021*\"reinforcement\" + 0.021*\"technique\" + 0.021*\"unsupervised\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000de19a-8dd4-40e5-966b-25442d67ce78",
   "metadata": {},
   "source": [
    "# Assign topics to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da343547-03b4-41b6-b1b6-1faba58a87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.032817908), (1, 0.03134291), (2, 0.031342912), (3, 0.90449625)]\n",
      "Document 2 - Topic: [(0, 0.924469), (1, 0.025126709), (2, 0.02512671), (3, 0.025277598)]\n",
      "Document 3 - Topic: [(0, 0.89203846), (1, 0.035840042), (2, 0.035840042), (3, 0.036281466)]\n",
      "Document 4 - Topic: [(0, 0.9055772), (1, 0.03137502), (2, 0.03137502), (3, 0.031672765)]\n"
     ]
    }
   ],
   "source": [
    "# Assign topics to documents\n",
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17631d05-4439-4d2d-a59a-fe43b98bf5f9",
   "metadata": {},
   "source": [
    "#                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
